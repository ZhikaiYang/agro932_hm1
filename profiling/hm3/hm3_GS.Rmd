---
title: "Genomic Selection practice"
author: "Zhikai Yang & Jinliang Yang"
date: "April 13th, 2020"
output: NULL
---


## Normalize the path:

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) 
knitr::opts_knit$set(root.dir=normalizePath('../../')) 
```

#2.Place the following system of equations in matrix form and solve it using R 
#5 X1 + 6 X2 = 3
#3 X1 -  4 X2 = -6


```{r}
A <- matrix(c(5,6,3,-4), nrow = 2, byrow = T)
Y <- matrix(c(3, -6), nrow = 2, byrow = T)
X = solve(A) %*% Y

#X1 = -0.632
#X2 = 1.026
```


#3. GBLUP vs. RR-BLUP

### GBLUP

Using genome-wide markers to quantify the amount of information extracted from relatives.

### RR-BLUP

Quantifying the effects of genome-wide markers from a population of related individuals.

--

----------

Theory has shown that GBLUP and RR-BLUP are equivalent:
- If the number of QTL is large
- No major QTL are present
- And the QTL are evenly distributed across the genome
> Fernando, 1998; Habier et al., 2007; Goddard, 2009.

---

# Framework of GS

<div align="center">
<img src="gs.png" height=200>
</div>

### Model training
In the context of GS, the lines with both genotype and phenotype data constitute a __training population__. => $\mathbf{\hat{m}}$

--

### Prediction
Predict the performance of the untested lines using their genotype data.
$\mathbf{\hat{y}} = \mathbf{1}\mu + \mathbf{Z} \mathbf{\hat{m}}$

---

# Modeling training

In the model training process, a __cross-validation__ method will be used within the training population.

- __k-fold__ cross-validation
  - The training population is divided in $k$ sets (i.e., 5-fold). 
  
- __delete-one__ (or __leave-one-out__) cross-validation
  - Use n-1 to train the model.

--

### Prediction accuracy

The prediction accuracy (denoted by $r_{MG}$) is the correlation between the true genotypic value and the genotypic value predicted from marker effects.

---

# A real world example: Loblolly pine data

Loblolly pine (Pinus taeda) data
>Resende Jr. et al. (2012) ([DOI: 10.1534/genetics.111.137026](http://dx.doi.org/10.1534/genetics.111.137026))


- __Mating Design__: 70 full-sib familes and 951 individuals in total using _a circular mating design_
- __Phenotyping__: 17 traits with distinct heritabilities and genetic architectures
- __Genotyping__: with 4,853 SNPs using the SNP array method. 
- Data can be downloaded from [zip](http://www.genetics.org/highwire/filestream/412827/field_highwire_adjunct_files/7/Loblolly_Pine_Resende_.zip) file. 

In this example, we will use the breeding values of root number data at age 10. 

```{r, eval=FALSE}
# read phenotype and SNP files
geno_file <- "https://jyanglab.com/img/data/Snp_Data.csv"

pheno <- read.csv("data/DATA_rootnum_age10_rootnum.csv", header=TRUE, stringsAsFactors = FALSE)
# hist(pheno$Derregressed_BV)
geno <- read.csv(geno_file, header=TRUE, stringsAsFactors = FALSE)
dim(geno)
# geno[1:10, 1:10]
```

---
# Loblolly pine data

### Remove missing phenotypes 

There are some accessions containing no phenotype. We need to remove these accessions first.

```{r, eval=FALSE}
na.index <-  which(is.na(pheno$Derregressed_BV))
# length(na.index)
pheno <- pheno[-na.index, ]
# Keep genotypes for these remaining lines
geno <- geno[geno$Genotype %in% pheno$Genotype, ]

# phenotypes 
y <- pheno$Derregressed_BV
y <- matrix(y, ncol=1)

# markers 
geno <- geno[,-1] # 925 x 4853
geno[geno == -9] <- NA
```


---
# SNP quality control

In the `geno` matrix, row indicates individual, column indicates SNPs.

### Missingness and MAF

```{r, eval=FALSE, echo=TRUE}
# missing rate
missing <- apply(geno, 2, function(x){sum(is.na(x))/length(x)})
# minor allele frequency
maf <- apply(geno, 2, function(x){
  frq <- mean(x, na.rm=TRUE)/2
  return(ifelse(frq > 0.5, 1-frq, frq))
})
```

--

#### Plot the results
```{r, eval=FALSE, echo=TRUE}
hist(missing, breaks=100, col="blue", xlab="SNP Missing rate")
hist(maf, breaks=100, col="blue", xlab="Minor Allele Freq")
```

---
# SNP quality control

Removing SNPs with high missing rate (missingness > 0.2) and low MAF (MAF < 0.05)

- Question: How many markers are removed?

```{r, eval=FALSE, echo=TRUE}
idx1 <- which(missing > 0.2) #154
idx2 <- which(maf < 0.05) #1647
idx <- unique(c(idx1, idx2)) #1784

geno2 <- geno[, -idx]
dim(geno2)
```


--

### Missing marker imputation

Replace missing marker genotypes with __mean values__. Then store the marker genotypes in a matrix object `Z`. 

```{r, eval=FALSE, echo=TRUE}
Z <- matrix(0, ncol=ncol(geno2), nrow=nrow(geno2))
for (j in 1:ncol(geno2)){
  #cat("j = ", j, '\n')
  Z[,j] <- ifelse(is.na(geno2[,j]), mean(geno2[,j], na.rm=TRUE), geno2[,j])
}
# sum(is.na(Z))
```

---

# Genomic relationship

### SNP Matrix standardization

Standardize the genotype matrix to have a mean of zero and variance of one. Save this matrix as `Zs`. 

```{r, eval=FALSE, echo=TRUE}
Zs <- scale(Z, center = TRUE, scale = TRUE)
# dimensions 
n <- nrow(Zs)
m <- ncol(Zs)
```

--

### Calcualte genomic relationship

- Compute the second genomic relationship matrix of VanRaden (2008) using the entire markers. 
- Then add a very small positive constant (e.g., 0.001) to the diagonal elements so that `G` matrix is invertible. 

```{r, eval=FALSE, echo=TRUE}
# Given matrices x and y as arguments, return a matrix cross-product. This is formally equivalent to (but usually slightly faster than) the call t(x) %*% y (crossprod) or x %*% t(y) (tcrossprod).
G <- tcrossprod(Zs) / ncol(Zs)
G <- G + diag(n)*0.001
```

---

# Solve MME for GBLUP

Set up mixed model equations (MME) by fitting the model:

  $$\mathbf{y = 1u + Zu + e}$$
  
- where $\mathbf{u}$ is the intercept, 
- $\mathbf{Z}$ is the incident matrix of individuals, 
- $\mathbf{u}$ is the additive marker effect, 
- and $\mathbf{e}$ is the residual. 

Directly take the inverse of LHS to obtain the solutions for GBLUP. Report the estimates of intercept and additive genetic values. Use $\lambda = 1.35$. 

```{r, eval=FALSE, echo=TRUE}
lambda <- 4.087116 # fit$Ve / fit$Vm
Ginv <- solve(G)
ones <- matrix(1, ncol=1, nrow=n)
Z <- diag(n)
# Given matrices x and y as arguments, return a matrix cross-product. This is formally equivalent to (but usually slightly faster than) the call t(x) %*% y (crossprod) or x %*% t(y) (tcrossprod).
LHS1 <- cbind(crossprod(ones), crossprod(ones, Z)) 
LHS2 <- cbind(crossprod(Z, ones), crossprod(Z) +  Ginv*lambda)
LHS <- rbind(LHS1, LHS2)
RHS <- rbind( crossprod(ones, y), crossprod(Z,y) )
sol <- solve(LHS, RHS)
head(sol)
tail(sol)
```

---

# R package: `rrBLUP`

Fit GBLUP by using the `mixed.solve` function in the [rrBLUP](https://cran.r-project.org/web/packages/rrBLUP/index.html) R package. 

- Report the estimates of intercept and additive genetic values. 
- Do they agree with previous estimates? 
- Also, report the estimated genomic heritability and the ratio of variance components $\lambda = \frac{V_e}{V_A}$. 

```{r, eval=FALSE, echo=TRUE}
#install.packages("rrBLUP")
library(rrBLUP)
fit <- mixed.solve(y = y, K=G)
# additive genetic variance
fit$Vu
# residual variance
fit$Ve
# intercept 
fit$beta
# additive genetic values
head(fit$u)
tail(fit$u)
# genomic h2
fit$Vu / (fit$Vu + fit$Ve)
# ratio of variance components 
fit$Ve / fit$Vu
# plot(x=sol[-1], y=fit$u)
```

---

# RR-BLUP

Set up mixed model equations (MME) by fitting the model $\mathbf{y = 1b + Zm + e}$, where $\mathbf{b}$ is the intercept, $\mathbf{Z}$ is the standardized marker genotypes (`Zs`), $\mathbf{m}$ is the additive marker genetic effects, and $\mathbf{e}$ is the residual. 

\begin{align*}
  \begin{bmatrix}
    \mathbf{\hat{b}} \\
    \mathbf{\hat{m}} \\
  \end{bmatrix}
  =
  \begin{bmatrix}
    \mathbf{X^{'}R^{-1}X} & \mathbf{X^{'}R^{-1}Z} \\
    \mathbf{Z^{'}R^{-1}X} & \mathbf{Z^{'}R^{-1}Z} + \mathbf{I} V_e/V_{M_i} \\
  \end{bmatrix}^{-1}
  \begin{bmatrix}
    \mathbf{X^{'}R^{-1}y} \\
    \mathbf{Z^{'}R^{-1}y} \\
  \end{bmatrix}
\end{align*}

Directly take the inverse of LHS to obtain the solutions for marker-based GBLUP (RR-BLUP). Report the estimates of intercept and marker additive genetic effects. Use $\lambda = 4326.212$. 

--

```{r, eval=FALSE, echo=TRUE}
lambda <- 12566.89 # fit$Ve / fit$Vu
ones <- matrix(1, ncol=1, nrow=n)
I <- diag(m)
LHS1 <- cbind(crossprod(ones), crossprod(ones, Zs)) 
LHS2 <- cbind(crossprod(Zs, ones), crossprod(Zs) +  I*lambda)
LHS <- rbind(LHS1, LHS2)
RHS <- rbind( crossprod(ones, y), crossprod(Zs,y) )
sol2 <- solve(LHS, RHS)
head(sol2)
tail(sol2)
```

---

# Use `rrBLUP` package

Fit RR-BLUP by using the `mixed.solve` function in the [rrBLUP](https://cran.r-project.org/web/packages/rrBLUP/index.html) R package. 

- Report the estimates of intercept and marker additive genetic effects. 
- o they agree with the estimates with the manual calculation? 
- Also, report the ratio of variance components $\lambda = \frac{V_e}{V_A}$. 

```{r, eval=FALSE, echo=TRUE}
library(rrBLUP)
fit2 <- mixed.solve(y = y, Z=Zs)
# marker additive genetic variance
fit2$Vu
# residual variance
fit2$Ve
# intercept 
fit2$beta
# marker additive genetic effects
head(fit2$u)
tail(fit2$u)
# ratio of variance components 
fit2$Ve / fit2$Vu

# plot(x=sol2[-1], y=fit2$u)
```

---

# K-fold validation

Repeat GBLUP but treat the first 600 individuals as a training set and predict the additive genetic values of the remaining individuals in the testing set. 
- What is the predictive correlation in the testing set? Use $\lambda = 1.348411$. 

```{r, eval=FALSE, echo=TRUE}

K = 10
d = round(n/K)
set.seed(0)
i.mix = sample(1:n)
folds = vector(mode="list",length=K)

for (k in 1:K) {
  folds[[k]] = i.mix[((k-1)*d+1):(k*d)]
}

p_K10_G <- rep(0.0, 10)

for (k in 1:K) {
cat("Fold",k,"\n")

i.trn = unlist(folds[-k])
i.tst = folds[[k]]


y.trn = y[i.trn]    # training responses

y.tst = y[i.tst]    # testing responses

Zs.trn <- Zs[i.trn,]
Zs.tst <- Zs[i.tst,]

Gtrn <- tcrossprod(Zs.trn) / ncol(Zs.trn)
Gtrn <- Gtrn + diag(length(y.trn))*0.001
Gtst.trn <- tcrossprod(Zs.tst, Zs.trn) / ncol(Zs.tst)
#Gtrn <- G[1:n.trn, 1:n.trn]
#Gtst.trn <- G[n.trn+1:n.tst, 1:n.trn]

lambda <- 4.087116 # fit$Ve / fit$Vu
Ginv.trn <- solve(Gtrn)
ones <- matrix(1, ncol=1, nrow=length(y.trn))
Z <- diag(length(y.trn))
LHS1 <- cbind(crossprod(ones), crossprod(ones, Z)) 
LHS2 <- cbind(crossprod(Z, ones), crossprod(Z) +  Ginv.trn*lambda)
LHS <- rbind(LHS1, LHS2)
RHS <- rbind( crossprod(ones, y.trn), crossprod(Z,y.trn) )
sol.trn <- solve(LHS, RHS)

# prediction
y.hat <- Gtst.trn %*% Ginv.trn %*% matrix(sol.trn[c(2:(length(y.trn)+1))])
p_K10_G[k] <- cor(y.hat, y.tst)

}



# plot(y.hat, y[(n.trn+1):n])
```

---

# K-fold validation

Repeat RR-BLUP but treat the first 600 individuals as a training set and predict the additive genetic values of the remaining individuals in the testing set. 
- What is the predictive correlation in the testing set? Use $\lambda = 4326.212$. 
- Also, compare this predictive correlation to the one from GBLUP. 

```{r, eval=FALSE, echo=TRUE}

K = 10
d = round(n/K)
set.seed(0)
i.mix = sample(1:n)
folds = vector(mode="list",length=K)

for (k in 1:K) {
  folds[[k]] = i.mix[((k-1)*d+1):(k*d)]
}

p_K10_rr <- rep(0.0, 10)

for (k in 1:K) {
cat("Fold",k,"\n")

i.trn = unlist(folds[-k])
i.tst = folds[[k]]


y.trn = y[i.trn]    # training responses

y.tst = y[i.tst]    # testing responses

Zs.trn <- Zs[i.trn,]
Zs.tst <- Zs[i.tst,]


lambda <- 12566.89 # fit$Ve / fit$Vu
ones <- matrix(1, ncol=1, nrow=length(y.trn))
I <- diag(m)
LHS1 <- cbind(crossprod(ones), crossprod(ones, Zs.trn)) 
LHS2 <- cbind(crossprod(Zs.trn, ones), crossprod(Zs.trn) +  I*lambda)
LHS <- rbind(LHS1, LHS2)
RHS <- rbind( crossprod(ones, y.trn), crossprod(Zs.trn, y.trn) )
sol.trn <- solve(LHS, RHS)

# prediction
y.hat2 <- Zs.tst %*% matrix(sol.trn[-1])
p_K10_rr[k] <- cor(y.hat2, y.tst)

}






# plot(y.hat2, y[(n.trn+1):n])
```


###Visualization
```{r}
library(ggplot2)

p_K10 <- data.frame(accuracy= c(p_K10_G, p_K10_rr), Method = c(rep("GBLUP", 10), rep("rrBLUP", 10))  )

dp <- ggplot(p_K10, aes(x=Method, y=accuracy, fill=Method)) + 
  geom_violin(trim=FALSE)+
  geom_boxplot(width=0.1, fill="white")+
  labs(title="Plot of Predication Accuracy by Methods",x="Mthod", y = "Predication Accuracy")
dp + theme_classic()

```

